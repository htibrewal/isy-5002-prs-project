{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["VxHEcI2tO_D5","5wEprOQWW-K8","Y0cyeRNxXdpw"],"authorship_tag":"ABX9TyNGBfM7ycCcs2TPAkGksMzC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data Preparation"],"metadata":{"id":"VxHEcI2tO_D5"}},{"cell_type":"code","source":["!pip install python-dotenv"],"metadata":{"id":"E8gyURpqPGMK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob\n","import os\n","import pandas as pd\n","from dotenv import load_dotenv\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from google.colab import drive\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n","import os"],"metadata":{"id":"aqjDO9SURoct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["load_dotenv()\n","\n","# to load whole folder of historical data for year 2023:\n","# drive.mount('/content/drive')\n","# historical_parking_base_folder = '/content/drive/My Drive/NUS-ISS AIS Projects/Project 2/Data/Parking CSV Data/2023'\n","# %cd {base_folder}\n","\n","historical_parking_df = pd.read_csv('/content/parking_data.csv')\n","\n","numerical_features = ['total_lots', 'available_lots']\n","categorical_features = [\n","    'fetch_timestamp',\n","    'car_park_number',\n","    'lot_type',\n","    'update_timestamp'\n","]\n","historical_parking_df.head()"],"metadata":{"id":"CjpzBu4MO95l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### For parsing through subfolders"],"metadata":{"id":"5wEprOQWW-K8"}},{"cell_type":"code","source":["\"\"\"def fetch_data_from_subfolders():\n","    subfolders = [f.path for f in os.scandir(historical_parking_base_folder) if f.is_dir()]\n","\n","    # read csv in a dataframe and put all the DataFrames in a list\n","    dfs = []\n","    for subfolder in subfolders:\n","        all_files = glob.glob(os.path.join(subfolder, '*.csv'))\n","        all_files.sort(key=lambda x: os.path.basename(x))\n","\n","        for file in all_files:\n","            df = pd.read_csv(file)\n","            dfs.append(df)\n","\n","    # concat all the dataframes\n","    return pd.concat(dfs, ignore_index=True)\"\"\""],"metadata":{"id":"GnJnI4cmWjkq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"def get_train_test_X_y(resultant_df, target=None, test_size=0.2):\n","    # prepare X & y (classification)\n","    X, y_encoded = get_X_y_encoded(resultant_df, target)\n","\n","    # train and test split for X & y\n","    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=test_size, random_state=42, stratify=y_encoded)\n","\n","    print(\"Shape of X_train = \", X_train.shape)\n","    print(\"Shape of X_test = \", X_test.shape)\n","    print(\"Shape of y_train = \", y_train.shape)\n","    print(\"Shape of y_test = \", y_test.shape)\n","\n","    return X_train, X_test, y_train, y_test\"\"\""],"metadata":{"id":"FqObpubJXSyU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"def get_X_y_encoded(resultant_df, target=None):\n","    if target is None:\n","        target = ['car_park_number']\n","\n","    X = resultant_df.drop(columns=target).to_numpy()\n","    y = resultant_df[target]\n","\n","    label_encoder = LabelEncoder()\n","    y_encoded = label_encoder.fit_transform(y)\n","\n","    return X, y_encoded\"\"\""],"metadata":{"id":"Q6MLx3TpXa1J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### For Single File From Year 2023"],"metadata":{"id":"Y0cyeRNxXdpw"}},{"cell_type":"code","source":["load_dotenv()\n","\n","def prepare_historical_parking_df_v2():\n","    # historical_parking_df = fetch_data_from_subfolders()\n","\n","    # Access the global historical_parking_df\n","    historical_parking_df = pd.read_csv('/content/parking_data.csv')\n","\n","    # feature engineering - updated timestamp\n","    historical_parking_df['update_timestamp'] = pd.to_datetime(historical_parking_df['update_timestamp'])\n","\n","    # get month, day_of_week, hour\n","    historical_parking_df['month'] = historical_parking_df['update_timestamp'].dt.month\n","    historical_parking_df['day_of_week'] = historical_parking_df['update_timestamp'].dt.weekday\n","    historical_parking_df['hour'] = historical_parking_df['update_timestamp'].dt.hour\n","\n","    # create cyclic features from month, day_of_week, hour\n","    historical_parking_df['sin_hour'] = np.sin(2 * np.pi * historical_parking_df['hour'] / 24)\n","    historical_parking_df['cos_hour'] = np.cos(2 * np.pi * historical_parking_df['hour'] / 24)\n","\n","    historical_parking_df['sin_day_of_week'] = np.sin(2 * np.pi * historical_parking_df['day_of_week'] / 7)\n","    historical_parking_df['cos_day_of_week'] = np.cos(2 * np.pi * historical_parking_df['day_of_week'] / 7)\n","\n","    historical_parking_df['sin_month'] = np.sin(2 * np.pi * historical_parking_df['month'] / 12)\n","    historical_parking_df['cos_month'] = np.cos(2 * np.pi * historical_parking_df['month'] / 12)\n","\n","    # drop not required features\n","    historical_parking_df = historical_parking_df.drop(\n","        columns=['sin_hour', 'cos_hour', 'sin_month' , 'cos_month' , 'month', 'day_of_week', 'hour'])\n","\n","    print(\"Historical parking data shape = \", historical_parking_df.shape)\n","    print(\"Historical parking data top 5\")\n","    print(historical_parking_df.head())\n","\n","    historical_parking_df = historical_parking_df[:10000]\n","\n","    return historical_parking_df"],"metadata":{"id":"jfr-KtyCPVXC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["historical_parking_df = prepare_historical_parking_df_v2()\n","\n","historical_parking_df.head()"],"metadata":{"collapsed":true,"id":"UE8ciOMEguLj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_parking_info_df_v2(folder_path = None):\n","\n","    parking_info_df = pd.read_csv('/content/HDBCarparkInformation.csv')\n","\n","    numerical_features = ['total_lots', 'available_lots', 'x_coord', 'y_coord']\n","    categorical_features = ['car_park_type', 'type_of_parking_system', 'short_term_parking',\n","    'free_parking', 'night_parking', 'car_park_basement']\n","\n","    parking_info_df = (parking_info_df\n","           .drop(columns=['address', 'gantry_height'])\n","           .rename(columns={'car_park_no': 'car_park_number'}))\n","\n","    encoder = OneHotEncoder()\n","    encoded_features = pd.DataFrame(encoder.fit_transform(parking_info_df[categorical_features]).toarray(),\n","            columns=encoder.get_feature_names_out())\n","    parking_info_df = parking_info_df.drop(columns=categorical_features).reset_index(drop=True)\n","\n","    print(\"Car park static info shape = \", parking_info_df.shape)\n","    print(\"Car park static info top 5\")\n","    print(parking_info_df.head())\n","\n","    parking_info_df = parking_info_df[:10000]\n","\n","    return pd.concat([parking_info_df, encoded_features], axis=1)"],"metadata":{"id":"Jy_iq-fkRwca"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_resultant_df_v2():\n","    # fetch prepared car lot info (static)\n","    parking_info_df = prepare_parking_info_df_v2()\n","\n","    # fetch prepared car parking data (historical)\n","    historical_parking_df = prepare_historical_parking_df_v2()\n","\n","    # prepare a resultant DataFrame\n","    resultant_df = pd.merge(historical_parking_df, parking_info_df, on='car_park_number', how='inner')\n","\n","    resultant_df = resultant_df[:10000]\n","\n","    scaler = MinMaxScaler()\n","    resultant_df[numerical_features] = scaler.fit_transform(resultant_df[numerical_features])\n","\n","    print(\"Resultant dataframe shape = \", resultant_df.shape)\n","    print(\"Resultant dataframe top 5\")\n","    print(resultant_df.head())\n","\n","    return resultant_df"],"metadata":{"id":"dccu2wdlR2YF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    print(prepare_resultant_df_v2())"],"metadata":{"id":"yYUxPSDBR6Fs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Pre-Processing"],"metadata":{"id":"RelfeM5XTSl1"}},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","from sklearn.metrics import accuracy_score, silhouette_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import glob"],"metadata":{"id":"ZgsRhwwBR_1Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"parking_base_folder = historical_parking_base_folder\n","\n","subfolders = [f.path for f in os.scandir(parking_base_folder) if f.is_dir()]\n","\n","\n","dfs = []\n","for subfolder in subfolders:\n","    all_files = glob.glob(os.path.join(subfolder, '*.csv'))\n","    all_files.sort(key=lambda x: os.path.basename(x))\n","\n","    for file in all_files:\n","        df = pd.read_csv(file)\n","        dfs.append(df)\n","\n","\n","!free -h\n","\n","parking_final_df = pd.concat(dfs, ignore_index=True)\"\"\""],"metadata":{"id":"ZQ9PTC9gYoh0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parking_final_df = prepare_historical_parking_df_v2()"],"metadata":{"id":"fiUsW6Nqa3-z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parking_final_df['occupied_lots'] = parking_final_df['total_lots'] - parking_final_df['available_lots']"],"metadata":{"id":"hLlK6Bm4hXCm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parking_final_df.head()"],"metadata":{"id":"EsgpsB1Uhjv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parking_info_df = pd.read_csv('/content/HDBCarparkInformation.csv')\n","\n","parking_info_df['car_park_type'] = pd.Categorical(parking_info_df['car_park_type']).codes\n","parking_info_df['type_of_parking_system'] = pd.Categorical(parking_info_df['type_of_parking_system']).codes\n","parking_info_df['short_term_parking'] = pd.Categorical(parking_info_df['short_term_parking']).codes\n","parking_info_df['free_parking'] = pd.Categorical(parking_info_df['free_parking']).codes\n","parking_info_df['night_parking'] = pd.Categorical(parking_info_df['night_parking']).codes\n","parking_info_df['car_park_decks'] = pd.Categorical(parking_info_df['car_park_decks']).codes\n","parking_info_df['car_park_basement'] = pd.Categorical(parking_info_df['car_park_basement']).codes\n","\n","parking_info_df.drop(labels=['gantry_height'], axis=1, inplace=True)\n","parking_info_df.rename(columns={'car_park_no': 'car_park_number'}, inplace=True)"],"metadata":{"id":"VaZcUIOLhmzX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parking_info_df.head()"],"metadata":{"id":"Jli6cze4lW4Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# merge the 2 results and then drop the columns that are not needed\n","\n","resultant_df = pd.merge(parking_final_df, parking_info_df, on='car_park_number', how='inner')\n","resultant_df.drop(['fetch_timestamp', 'lot_type', 'address'], axis=1, inplace=True)\n","resultant_df.head()"],"metadata":{"id":"K__Q3p9_lZyM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resultant_df['update_timestamp'] = pd.to_datetime(resultant_df['update_timestamp'])\n","\n","resultant_df['update_year'] = resultant_df['update_timestamp'].dt.year\n","resultant_df['update_month'] = resultant_df['update_timestamp'].dt.month\n","resultant_df['update_day'] = resultant_df['update_timestamp'].dt.day\n","resultant_df['update_hour'] = resultant_df['update_timestamp'].dt.hour\n","resultant_df['update_minute'] = resultant_df['update_timestamp'].dt.minute\n","resultant_df['update_second'] = resultant_df['update_timestamp'].dt.second\n","resultant_df.drop('update_timestamp', axis=1, inplace=True)\n","\n","resultant_df.head()"],"metadata":{"id":"8fwcOQ81l0C4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filtered_df = resultant_df[resultant_df['car_park_number'] == 'HE12']\n","filtered_df.head()"],"metadata":{"id":"AORgxC77yVKI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resultant_df_small = resultant_df[:100]\n","X = resultant_df_small.drop('car_park_number', axis=1)\n","y = resultant_df_small['car_park_number']"],"metadata":{"id":"yO8SC_iPl4gr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X.head()"],"metadata":{"id":"OxDtEjrTl_HB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_encoded = LabelEncoder().fit_transform(y)"],"metadata":{"id":"7PWai85GmBvR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.unique(y_encoded).shape"],"metadata":{"id":"08S0qAjZmFET"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mutual info of each feature with classification output\n","from sklearn.feature_selection import mutual_info_classif\n","\n","mi_scores = mutual_info_classif(X, y)\n","mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n","mi_scores = mi_scores.sort_values(ascending=False)\n","mi_scores"],"metadata":{"id":"6cLx6PxqmHJn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# correlation of features with each other\n","X.corr()"],"metadata":{"id":"IaUX7Or3mNQM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Visualization of correlation\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Calculate the correlation matrix\n","correlation_matrix = X.corr()\n","\n","# Create a heatmap of the correlation matrix\n","plt.figure(figsize=(12, 10))\n","sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n","plt.title('Correlation Matrix of Features')\n","plt.show()"],"metadata":{"id":"iRxhwHw_mZ3E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Support Vector Classifier"],"metadata":{"id":"cjt-f1cRmsVH"}},{"cell_type":"code","source":["from sklearn.svm import SVC\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"],"metadata":{"id":"1CXaUKN_my0X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n","\n","# Create an SVC model with default parameters\n","svc_model = SVC(kernel='linear', C=1.0, decision_function_shape='ovr')  # You can try other kernels like 'rbf' or 'poly'\n","\n","# Fit the model to the training data\n","svc_model.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = svc_model.predict(X_test)"],"metadata":{"id":"QeaJBq5k2uvr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy * 100:.2f}%\")\n","\n","# Print detailed classification report\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_pred))\n","\n","# Display confusion matrix\n","print(\"Confusion Matrix:\")\n","print(confusion_matrix(y_test, y_pred))"],"metadata":{"id":"SFOnUFZn2X4f"},"execution_count":null,"outputs":[]}]}